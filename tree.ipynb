{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>club_id</th>\n",
       "      <th>own_goals</th>\n",
       "      <th>own_position</th>\n",
       "      <th>own_manager_name</th>\n",
       "      <th>opponent_id</th>\n",
       "      <th>opponent_goals</th>\n",
       "      <th>opponent_position</th>\n",
       "      <th>opponent_manager_name</th>\n",
       "      <th>hosting</th>\n",
       "      <th>is_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1468</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holger Bachthaler</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Armin Veh</td>\n",
       "      <td>Home</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jürgen Luginger</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Robin Dutt</td>\n",
       "      <td>Home</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2036</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frank Schmidt</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alexander Schmidt</td>\n",
       "      <td>Home</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jürgen Klopp</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Torsten Lieberknecht</td>\n",
       "      <td>Home</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Torsten Lieberknecht</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Armin Veh</td>\n",
       "      <td>Home</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139265</th>\n",
       "      <td>1132</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vincent Kompany</td>\n",
       "      <td>34888</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neil Wood</td>\n",
       "      <td>Away</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139266</th>\n",
       "      <td>1082</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Bruno Génésio</td>\n",
       "      <td>618</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Olivier Dall'Oglio</td>\n",
       "      <td>Away</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139267</th>\n",
       "      <td>276</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Paolo Zanetti</td>\n",
       "      <td>398</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Marco Baroni</td>\n",
       "      <td>Away</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139268</th>\n",
       "      <td>409</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pepijn Lijnders</td>\n",
       "      <td>338</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oleksandr Shovkovskyi</td>\n",
       "      <td>Away</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139269</th>\n",
       "      <td>1837</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Giannis Tatsis</td>\n",
       "      <td>4602</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stelios Arsenos</td>\n",
       "      <td>Away</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139270 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        club_id  own_goals  own_position      own_manager_name  opponent_id  \\\n",
       "0          1468          0           NaN     Holger Bachthaler           24   \n",
       "1             1          3           NaN       Jürgen Luginger           86   \n",
       "2          2036          4           NaN         Frank Schmidt           72   \n",
       "3            16          2           1.0          Jürgen Klopp           23   \n",
       "4            23          0          18.0  Torsten Lieberknecht           24   \n",
       "...         ...        ...           ...                   ...          ...   \n",
       "139265     1132          4           NaN       Vincent Kompany        34888   \n",
       "139266     1082          0           8.0         Bruno Génésio          618   \n",
       "139267      276          1           7.0         Paolo Zanetti          398   \n",
       "139268      409          2           NaN       Pepijn Lijnders          338   \n",
       "139269     1837          4           NaN        Giannis Tatsis         4602   \n",
       "\n",
       "        opponent_goals  opponent_position  opponent_manager_name hosting  \\\n",
       "0                    2                NaN              Armin Veh    Home   \n",
       "1                    1                NaN             Robin Dutt    Home   \n",
       "2                    5                NaN      Alexander Schmidt    Home   \n",
       "3                    1               15.0   Torsten Lieberknecht    Home   \n",
       "4                    2               11.0              Armin Veh    Home   \n",
       "...                ...                ...                    ...     ...   \n",
       "139265               0                NaN              Neil Wood    Away   \n",
       "139266               1               16.0     Olivier Dall'Oglio    Away   \n",
       "139267               2                6.0           Marco Baroni    Away   \n",
       "139268               0                NaN  Oleksandr Shovkovskyi    Away   \n",
       "139269               1                NaN        Stelios Arsenos    Away   \n",
       "\n",
       "        is_win  \n",
       "0            0  \n",
       "1            1  \n",
       "2            0  \n",
       "3            1  \n",
       "4            0  \n",
       "...        ...  \n",
       "139265       1  \n",
       "139266       0  \n",
       "139267       0  \n",
       "139268       1  \n",
       "139269       1  \n",
       "\n",
       "[139270 rows x 10 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/transfer_data/club_games.csv\")\n",
    "df = df.drop('game_id',axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up data\n",
    "- Change datatype\n",
    "- Drop NaN rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hosting'] = df['hosting'].apply(lambda x : True if x == \"Home\" else False).astype(bool)\n",
    "df['is_win'] = df['is_win'].apply(lambda x : True if x == 1 else False).astype(bool)\n",
    "df['opponent_position'] = df['opponent_position'].astype('Int64')\n",
    "df['own_position'] = df['own_position'].astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows with any NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "club_id                   int64\n",
       "own_goals                 int64\n",
       "own_position              Int64\n",
       "own_manager_name         object\n",
       "opponent_id               int64\n",
       "opponent_goals            int64\n",
       "opponent_position         Int64\n",
       "opponent_manager_name    object\n",
       "hosting                    bool\n",
       "is_win                     bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
    "        \"\"\"Constructor for a single node\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tfeature_index (_type_, optional): _description_. Defaults to None.\n",
    "\t\t\tthreshold (_type_, optional): _description_. Defaults to None.\n",
    "\t\t\tleft (_type_, optional): _description_. Defaults to None.\n",
    "\t\t\tright (_type_, optional): _description_. Defaults to None.\n",
    "\t\t\tinfo_gain (_type_, optional): _description_. Defaults to None.\n",
    "\t\t\tvalue (_type_, optional): _description_. Defaults to None.\n",
    "\t\t\"\"\"\n",
    "        # For Decision Nodes\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.info_gain = info_gain\n",
    "        \n",
    "        # For Leaf Nodes\n",
    "        self.value = value\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier():\n",
    "    def __init__(self, min_samples_split=2, max_depth=2):\n",
    "        # Init the root of the tree\n",
    "        self.root = None\n",
    "        \n",
    "        # Stop Condition\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def build_tree(self, dataset, curr_depth=0):\n",
    "        \"\"\"Recursively build a decision tree\n",
    "\n",
    "        Args:\n",
    "            dataset (_type_): _description_\n",
    "            curr_depth (int, optional): _description_. Defaults to 0.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Split features and targets\n",
    "        X, Y = dataset[:, :-1], dataset[:,:-1]\n",
    "        \n",
    "        # Extract num samples, num features\n",
    "        num_samples , num_features = np.shape(X)\n",
    "        \n",
    "        # Split til stopping condition\n",
    "        if num_samples >= self.min_samples_split and curr_depth <= self.max_depth:\n",
    "            # Find best split\n",
    "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
    "            # Check if info gain is pos.\n",
    "            # Because info gain < 0 means we are splitting a pure node (Node consisting of only one class...)\n",
    "            # Alr ideal node\n",
    "            if best_split['info_gain'] > 0:\n",
    "                # recur left\n",
    "                left_subtree = self.build_tree(best_split['dataset_left'], curr_depth + 1)\n",
    "                # recur right\n",
    "                right_subtree = self.build_tree(best_split['dataset_right'], curr_depth + 1)\n",
    "                # Return decision node\n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"], left_subtree, right_subtree, best_split[\"info_gain\"])\n",
    "        \n",
    "        # Stopping condition met\n",
    "        # Compute Leaf Node\n",
    "        leaf_value = self.calculate_leaf_value(Y)\n",
    "        # Return leaf node\n",
    "        return Node(value=leaf_value)\n",
    "    \n",
    "    def get_best_split(self, dataset, num_samples, num_features):\n",
    "        \"\"\"Function to find the best split\n",
    "\n",
    "        Args:\n",
    "            dataset (_type_): _description_\n",
    "            num_samples (_type_): _description_\n",
    "            num_features (_type_): _description_\n",
    "        \"\"\"\n",
    "        \n",
    "        # Dictionary to store the best split\n",
    "        best_split = {}\n",
    "        max_info_gain = -float(\"inf\")\n",
    "        \n",
    "        # Iterate over all features\n",
    "        for feature_index in range(num_features):\n",
    "            feature_values = dataset[:, feature_index]\n",
    "            # Use unique to remove duplicate feature values and only iterate over unique feature values\n",
    "            possible_thresholds = np.unique(feature_values)\n",
    "            for threshold in possible_thresholds:\n",
    "                # Iterate over all possible thresholds\n",
    "                # Get current split\n",
    "                dataset_left , dataset_right = self.split(dataset, feature_index, threshold)\n",
    "                # Check if childs are not null (Check for empty child nodes)\n",
    "                if len(dataset_left) > 0 and len(dataset_right) > 0:\n",
    "                    # Extract only target values from datasets\n",
    "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
    "                    # Compute information gain\n",
    "                    curr_info_gain = self.information_gain(y, left_y, right_y, \"gini\")\n",
    "                    # Update the best split if needed\n",
    "                    if curr_info_gain > max_info_gain:\n",
    "                        best_split[\"feature_index\"] = feature_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"dataset_left\"] = dataset_left\n",
    "                        best_split[\"dataset_right\"] = dataset_right\n",
    "                        best_split[\"info_gain\"] = curr_info_gain\n",
    "                        max_info_gain = curr_info_gain\n",
    "        \n",
    "        # Return best split\n",
    "        return best_split\n",
    "    \n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "        \"\"\"Function to split the data based on feature_index and threshold\n",
    "\n",
    "        Args:\n",
    "            dataset (_type_): _description_\n",
    "            feature_index (_type_): _description_\n",
    "            threshold (_type_): _description_\n",
    "        \"\"\"\n",
    "        # Left Child\n",
    "        dataset_left = np.array([row for row in dataset if row[feature_index] <= threshold])\n",
    "        # Right Child\n",
    "        dataset_right = np.array([row for row in dataset if row[feature_index] > threshold])\n",
    "        \n",
    "        return dataset_left, dataset_right\n",
    "    \n",
    "    def information_gain(self, parent, left_child, right_child, mode=\"entropy\"):\n",
    "        \"\"\"Function to calculate information gain\n",
    "\n",
    "        Args:\n",
    "            parent (_type_): _description_\n",
    "            left_child (_type_): _description_\n",
    "            right_child (_type_): _description_\n",
    "            mode (str, optional): _description_. Defaults to \"entropy\".\n",
    "        \"\"\"\n",
    "        # Weight = Relative size of a child compared to parent\n",
    "        left_weight = len(left_child) / len(parent)\n",
    "        right_weight = len(right_child) / len(parent)\n",
    "        \n",
    "        if mode==\"gini\":\n",
    "            gain = self.gini_index(parent) - (left_weight * self.gini_index(left_child) + right_weight * self.gini_index(right_child))\n",
    "        else:\n",
    "            gain = self.entropy(parent) - (left_weight * self.entropy(left_child) + right_weight * self.entropy(right_child))\n",
    "            \n",
    "        return gain\n",
    "    \n",
    "    def entropy(self, y):\n",
    "        \"\"\"Function to compute Entropy of our dataset Y\n",
    "\n",
    "        Args:\n",
    "            y (_type_): _description_\n",
    "        \"\"\"\n",
    "        class_labels = np.unique(y)\n",
    "        entropy = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y==cls]) / len(y)\n",
    "            entropy += -1 * p_cls * np.log2(p_cls)\n",
    "        \n",
    "        return entropy\n",
    "\n",
    "    def gini_index(self, y):\n",
    "        \"\"\"Function to calculate Gini Index\n",
    "\n",
    "        Args:\n",
    "            y (_type_): _description_\n",
    "        \"\"\"\n",
    "        class_labels = np.unique(y)\n",
    "        gini = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y==cls]) / len(y)\n",
    "            gini += p_cls ** 2\n",
    "        \n",
    "        return 1 - gini\n",
    "        \n",
    "    def calculate_leaf_value(self, Y):\n",
    "        \"\"\"Function to compute leaf node\n",
    "\n",
    "        Args:\n",
    "            Y (_type_): _description_\n",
    "        \"\"\"\n",
    "        # Majority class in the node (Return most occuring class in Y)\n",
    "        Y = list(Y)\n",
    "        return max(Y, key=Y.count)\n",
    "    \n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        \"\"\"Function to print out the decision tree\n",
    "\n",
    "        Args:\n",
    "            tree (_type_, optional): _description_. Defaults to None.\n",
    "            indent (str, optional): _description_. Defaults to \" \".\n",
    "        \"\"\"\n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "        \n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "        else:\n",
    "            print(\"X_\" + str(tree.feature_index), \"<=\", tree.threshold, \"?\", tree.info_gain) \n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.left, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.right, indent + indent)\n",
    "            \n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"Funtion to train the tree\n",
    "\n",
    "        Args:\n",
    "            X (_type_): _description_\n",
    "            Y (_type_): _description_\n",
    "        \"\"\"\n",
    "        dataset = np.concatenate((X,Y), axis=1)\n",
    "        self.root = self.build_tree(dataset)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"Function to predict new dataset\n",
    "\n",
    "        Args:\n",
    "            X (_type_): _description_\n",
    "        \"\"\"\n",
    "        predictions = [self.make_prediction(x, self.root) for x in X]\n",
    "        return predictions\n",
    "    \n",
    "    def make_prediction(self, x, tree):\n",
    "        \"\"\"Function to predict a single data point\n",
    "\n",
    "        Args:\n",
    "            x (_type_): _description_\n",
    "            tree (_type_): _description_\n",
    "        \"\"\"\n",
    "        \n",
    "        if tree.value != None:\n",
    "            # If node == Leaf node, return value\n",
    "            return tree.value\n",
    "        # Not a leaf node\n",
    "        # Extract feature value\n",
    "        feature_value = x[tree.feature_index]\n",
    "        if feature_value <= tree.threshold:\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "Y = df.iloc[:, -1].values.reshape(-1, 1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test =train_test_split(X, Y, test_size=0.001, random_state=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m classifier = DecisionTreeClassifier(min_samples_split=\u001b[32m100\u001b[39m, max_depth=\u001b[32m5\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m classifier.print_tree()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 185\u001b[39m, in \u001b[36mDecisionTreeClassifier.fit\u001b[39m\u001b[34m(self, X, Y)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Funtion to train the tree\u001b[39;00m\n\u001b[32m    179\u001b[39m \n\u001b[32m    180\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[33;03m    X (_type_): _description_\u001b[39;00m\n\u001b[32m    182\u001b[39m \u001b[33;03m    Y (_type_): _description_\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    184\u001b[39m dataset = np.concatenate((X,Y), axis=\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[38;5;28mself\u001b[39m.root = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mDecisionTreeClassifier.build_tree\u001b[39m\u001b[34m(self, dataset, curr_depth)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Split til stopping condition\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_samples >= \u001b[38;5;28mself\u001b[39m.min_samples_split \u001b[38;5;129;01mand\u001b[39;00m curr_depth <= \u001b[38;5;28mself\u001b[39m.max_depth:\n\u001b[32m     26\u001b[39m     \u001b[38;5;66;03m# Find best split\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     best_split = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_best_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     \u001b[38;5;66;03m# Check if info gain is pos.\u001b[39;00m\n\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# Because info gain < 0 means we are splitting a pure node (Node consisting of only one class...)\u001b[39;00m\n\u001b[32m     30\u001b[39m     \u001b[38;5;66;03m# Alr ideal node\u001b[39;00m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m best_split[\u001b[33m'\u001b[39m\u001b[33minfo_gain\u001b[39m\u001b[33m'\u001b[39m] > \u001b[32m0\u001b[39m:\n\u001b[32m     32\u001b[39m         \u001b[38;5;66;03m# recur left\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mDecisionTreeClassifier.get_best_split\u001b[39m\u001b[34m(self, dataset, num_samples, num_features)\u001b[39m\n\u001b[32m     62\u001b[39m possible_thresholds = np.unique(feature_values)\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m possible_thresholds:\n\u001b[32m     64\u001b[39m     \u001b[38;5;66;03m# Iterate over all possible thresholds\u001b[39;00m\n\u001b[32m     65\u001b[39m     \u001b[38;5;66;03m# Get current split\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     dataset_left , dataset_right = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# Check if childs are not null (Check for empty child nodes)\u001b[39;00m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dataset_left) > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dataset_right) > \u001b[32m0\u001b[39m:\n\u001b[32m     69\u001b[39m         \u001b[38;5;66;03m# Extract only target values from datasets\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 94\u001b[39m, in \u001b[36mDecisionTreeClassifier.split\u001b[39m\u001b[34m(self, dataset, feature_index, threshold)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Function to split the data based on feature_index and threshold\u001b[39;00m\n\u001b[32m     87\u001b[39m \n\u001b[32m     88\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     91\u001b[39m \u001b[33;03m    threshold (_type_): _description_\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# Left Child\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m dataset_left = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# Right Child\u001b[39;00m\n\u001b[32m     96\u001b[39m dataset_right = np.array([row \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m dataset \u001b[38;5;28;01mif\u001b[39;00m row[feature_index] > threshold])\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(min_samples_split=100, max_depth=5)\n",
    "classifier.fit(X_train, Y_train)\n",
    "classifier.print_tree()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
